{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ae25c8e-fcae-46fe-986a-43a66d05288a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import re\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "289a0509-eca1-4f48-b262-74db07248653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder setup\n",
    "train_dir = 'train'\n",
    "test_dir = 'test'\n",
    "\n",
    "# Natural sort helper\n",
    "def natural_key(s):\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split('([0-9]+)', s)]\n",
    "\n",
    "# Image loader\n",
    "def load_images_from_folder(folder, limit=None):\n",
    "    images = []\n",
    "    filenames = []\n",
    "    count = 0\n",
    "    for filename in sorted(os.listdir(folder), key=natural_key):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "            img_path = os.path.join(folder, filename)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "            if img is not None:\n",
    "                images.append(img)\n",
    "                filenames.append(filename)\n",
    "                count += 1\n",
    "                if limit and count >= limit:\n",
    "                    break\n",
    "    return images, filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c1f7431-d156-44b7-bb1d-0a714b573179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hough line removal\n",
    "def remove_lines_with_hough_enhanced(gray_img, binary_img):\n",
    "    equalized = cv2.equalizeHist(gray_img)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 1))\n",
    "    enhanced = cv2.morphologyEx(equalized, cv2.MORPH_CLOSE, kernel)\n",
    "    edges = cv2.Canny(enhanced, 30, 120)\n",
    "\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=25, minLineLength=20, maxLineGap=10)\n",
    "    cleaned = binary_img.copy()\n",
    "\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            angle = np.degrees(np.arctan2((y2 - y1), (x2 - x1)))\n",
    "            if 10 < abs(angle) < 170:\n",
    "                cv2.line(cleaned, (x1, y1), (x2, y2), 255, 2)\n",
    "    return cleaned\n",
    "\n",
    "#  Morphological scratch line removal \n",
    "def remove_scratch_lines_morphological(binary_img):\n",
    "    h_kernel = np.ones((1, 3), np.uint8)\n",
    "    v_kernel = np.ones((3, 1), np.uint8)\n",
    "    s_kernel = np.ones((2, 2), np.uint8)\n",
    "    \n",
    "    h_opening = cv2.morphologyEx(binary_img, cv2.MORPH_OPEN, h_kernel)\n",
    "    v_opening = cv2.morphologyEx(h_opening, cv2.MORPH_OPEN, v_kernel)\n",
    "    cleaned = cv2.morphologyEx(v_opening, cv2.MORPH_OPEN, s_kernel)\n",
    "\n",
    "    closing_kernel = np.ones((2, 2), np.uint8)\n",
    "    cleaned = cv2.morphologyEx(cleaned, cv2.MORPH_CLOSE, closing_kernel)\n",
    "    \n",
    "    return cleaned\n",
    "\n",
    "# Combined approach\n",
    "def remove_scratch_lines_combined(gray_img, binary_img):\n",
    "    hough_cleaned = remove_lines_with_hough_enhanced(gray_img, binary_img)\n",
    "    morph_cleaned = remove_scratch_lines_morphological(hough_cleaned)\n",
    "    return morph_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a27c6e-0cf4-4e59-9b42-80b15d73a797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "13578d7c-eef7-43a5-b65f-fa3afda5acd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_color_threshold(color, threshold=30):\n",
    "    \"\"\"\n",
    "    Safely compute color thresholds while preventing integer overflow\n",
    "    \n",
    "    Parameters:\n",
    "    color (numpy.ndarray): RGB color values\n",
    "    threshold (int): Range of color variation to include\n",
    "    \n",
    "    Returns:\n",
    "    tuple: Lower and upper color bounds\n",
    "    \"\"\"\n",
    "    # Convert to unsigned 8-bit integer to prevent overflow\n",
    "    color_u8 = color.astype(np.uint8)\n",
    "    \n",
    "    # Compute lower and upper bounds\n",
    "    lower_bound = np.maximum(color_u8.astype(np.int16) - threshold, 0).astype(np.uint8)\n",
    "    upper_bound = np.minimum(color_u8.astype(np.int16) + threshold, 255).astype(np.uint8)\n",
    "    \n",
    "    return lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "a4bbe92b-4cc5-4b3f-878e-ccc8764546a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_overlapping_characters(img, color_threshold_percent=5):\n",
    "    # Flatten the image and count color frequencies\n",
    "    pixels = img.reshape(-1, 3)\n",
    "    unique_colors, counts = np.unique(pixels, axis=0, return_counts=True)\n",
    "    \n",
    "    # Calculate percentage of each color\n",
    "    total_pixels = pixels.shape[0]\n",
    "    color_percentages = counts / total_pixels * 100\n",
    "    \n",
    "    # Select colors that appear in at least 10% of the image\n",
    "    significant_colors = unique_colors[color_percentages >= color_threshold_percent]\n",
    "    white = np.array([255, 255, 255])\n",
    "    significant_colors = significant_colors[~np.all(significant_colors == white, axis=1)]\n",
    "    \n",
    "    # Create masks for each significant color with color thresholding\n",
    "    masks = []\n",
    "    for color in significant_colors:\n",
    "        # Define color threshold (to include similar shades)\n",
    "        lower_bound, upper_bound = safe_color_threshold(color)\n",
    "        # Create mask\n",
    "        mask = cv2.inRange(img, lower_bound, upper_bound)\n",
    "\n",
    "        masks.append(mask)\n",
    "    \n",
    "    # Sort masks by leftmost pixel\n",
    "    def get_leftmost_pixel(mask):\n",
    "        # Find non-zero coordinates\n",
    "        coords = np.column_stack(np.where(mask > 0))\n",
    "        return coords[:, 1].min() if coords.size > 0 else float('inf')\n",
    "    \n",
    "    sorted_masks = sorted(masks, key=get_leftmost_pixel)\n",
    "    \n",
    "    # Extract individual character images with white background\n",
    "    character_images = []\n",
    "    for mask in sorted_masks:\n",
    "        # Create a white background image\n",
    "        white_background = np.ones_like(img) * 255\n",
    "        \n",
    "        # Copy the character onto the white background using the mask\n",
    "        character = white_background.copy()\n",
    "        character[mask > 0] = img[mask > 0]\n",
    "        \n",
    "        character_images.append(character)\n",
    "    \n",
    "    return character_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6592c80-2819-4e8e-ab47-49de5dfb934d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b56d730d-8598-4437-8705-61e80b3d55ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_letters(binary, color_img, color=False, min_area=50):\n",
    "    binary_flipped = cv2.bitwise_not(binary)\n",
    "\n",
    "    # Step 4: Find contours (external only)\n",
    "    contours, _ = cv2.findContours(binary_flipped, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Step 5: Extract and filter bounding boxes\n",
    "    boxes = []\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if w * h >= min_area:\n",
    "            boxes.append((x, y, w, h))\n",
    "\n",
    "    # Step 6: Sort boxes left to right\n",
    "    boxes = sorted(boxes, key=lambda b: b[0])\n",
    "\n",
    "    # Step 7: Crop characters\n",
    "    letters = []\n",
    "    for (x, y, w, h) in boxes:\n",
    "        if color:\n",
    "            char_img = color_img[y:y+h, x:x+w]\n",
    "            separated = separate_overlapping_characters(char_img)\n",
    "            for separated_img in separated:\n",
    "                gray = cv2.cvtColor(separated_img, cv2.COLOR_BGR2GRAY)\n",
    "                binary = cv2.adaptiveThreshold(\n",
    "                        gray, 255,\n",
    "                        cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "                        cv2.THRESH_BINARY,\n",
    "                        blockSize=15,\n",
    "                        C=3\n",
    "                    )\n",
    "                letters.append(binary)\n",
    "            \n",
    "        else:\n",
    "            char_img = binary[y:y+h, x:x+w]\n",
    "            letters.append(char_img)\n",
    "\n",
    "    return letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1400cade-cee1-4091-93fa-634cb9c190e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing pipeline\n",
    "def preprocess_image(img, resize_to=None, color=False):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    binary = cv2.adaptiveThreshold(\n",
    "        gray, 255,\n",
    "        cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "        cv2.THRESH_BINARY,\n",
    "        blockSize=15,\n",
    "        C=3\n",
    "    )\n",
    "\n",
    "    cleaned = remove_scratch_lines_combined(gray, binary)\n",
    "    \n",
    "    mask = cv2.bitwise_not(cleaned)\n",
    "    white_background = np.ones_like(img) * 255\n",
    "    color_cleaned = white_background.copy()\n",
    "    color_cleaned[mask > 0] = img[mask > 0]\n",
    "    \n",
    "    letters = get_letters(cleaned, color_cleaned, color=color)\n",
    "    \n",
    "    \n",
    "    if resize_to:\n",
    "        results = []\n",
    "        for letter in letters:\n",
    "            letter = cv2.resize(letter, resize_to)\n",
    "            results.append(letter)\n",
    "    \n",
    "        return results\n",
    "    else:\n",
    "        return letters\n",
    "    \n",
    "    # return gray, binary, cleaned, color_cleaned\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a3f761d-120e-48ff-9edf-99211ddedb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image(img, angle):\n",
    "    # Get image center and rotation matrix\n",
    "    (h, w) = img.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    rot_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "\n",
    "    # Calculate bounding box size to fit rotated image\n",
    "    cos = np.abs(rot_matrix[0, 0])\n",
    "    sin = np.abs(rot_matrix[0, 1])\n",
    "    new_w = int((h * sin) + (w * cos))\n",
    "    new_h = int((h * cos) + (w * sin))\n",
    "\n",
    "    # Adjust rotation matrix for translation\n",
    "    rot_matrix[0, 2] += (new_w / 2) - center[0]\n",
    "    rot_matrix[1, 2] += (new_h / 2) - center[1]\n",
    "\n",
    "    # Perform rotation with white background\n",
    "    if len(img.shape) == 2:\n",
    "        border_value = 255\n",
    "    else:\n",
    "        border_value = (255, 255, 255)\n",
    "\n",
    "    rotated = cv2.warpAffine(img, rot_matrix, (new_w, new_h), borderValue=border_value)\n",
    "\n",
    "    return rotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42d3a95e-e3ae-44ed-a7e4-c79c1e9c8395",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_letter_dir = 'train_letter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d653dcd2-f2d4-4e98-a40e-211c560b58a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "angles = [-30, -20, -10, 10, 20, 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01df1e14-cde0-4dfc-8838-10610530fd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "filename_count = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "418126e4-22e6-4b92-8b11-7f45083dc99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def save_image_from_array(img_array, save_path):\n",
    "    if len(img_array.shape) == 3 and img_array.shape[2] == 3:\n",
    "        # Convert BGR (OpenCV) to RGB (PIL)\n",
    "        img_array = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    img = Image.fromarray(img_array.astype(np.uint8))\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    img.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "add5a4f1-29e0-475b-ba5e-7423ca97c7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\\0024miih-0.png\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "miscount = 0\n",
    "for filename in sorted(os.listdir(train_dir)):\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "        img_path = os.path.join(train_dir, filename)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        if img is None:\n",
    "            continue\n",
    "                \n",
    "        label = filename.split('-')[0]\n",
    "        chars = preprocess_image(img, resize_to=None, color=False)\n",
    "\n",
    "        \n",
    "        if len(label) != len(chars):\n",
    "            miscount += 1\n",
    "        \n",
    "        for i in range(min(len(label), len(chars))):\n",
    "            letter = label[i]\n",
    "            char = chars[i]\n",
    "            new_name = 'img-' + str(filename_count[letter]) + '.png'\n",
    "            filename_count[letter] += 1\n",
    "            save_image_from_array(char, os.path.join(train_letter_dir, letter, new_name))\n",
    "            random_numbers = random.sample(range(len(angles)), 3)              \n",
    "            for no in random_numbers:\n",
    "                new_char = rotate_image(char, angles[no])\n",
    "                new_name ='img-' + str(filename_count[letter]) + '.png'\n",
    "                filename_count[letter] += 1\n",
    "                save_image_from_array(new_char, os.path.join(train_letter_dir, letter, new_name))\n",
    "            \n",
    "    count += 1\n",
    "    if count % 500 == 0:\n",
    "        print(f\"Done with {count} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c8963e-4a46-4a1b-a093-3bf4aa0aa807",
   "metadata": {},
   "outputs": [],
   "source": [
    "micount"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs4243",
   "language": "python",
   "name": "cs4243"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
